{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The idea is to create a json file of natural language questions from the url of the most run queries in a given Explore/Model.\n",
        "This can then be uploaded to the examples table in BigQuery."
      ],
      "metadata": {
        "id": "NjUWiCR8PQ5s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-eOcTAPcTu4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "pip install looker_sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'GCP_PROJECT_ID'\n",
        "location = 'GCP_LOCATION' # us-central1"
      ],
      "metadata": {
        "id": "j4eiRr5-hU_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "phWGx58TgpVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project {project_id}\n",
        "!gcloud auth application-default set-quota-project {project_id}"
      ],
      "metadata": {
        "id": "102RLctahHm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google\n",
        "from google.auth import credentials\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "# Assuming gcloud authentication is done, you can now use google-auth to get credentials.\n",
        "credentials, project = google.auth.default()\n",
        "\n",
        "if credentials.expired:\n",
        "    credentials.refresh(Request())\n",
        "\n",
        "print(f\"Authenticated to project: {project}\")\n"
      ],
      "metadata": {
        "id": "UVhKM1tdh007"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import looker_sdk\n",
        "import json\n",
        "import os\n",
        "import vertexai\n",
        "from vertexai.preview.generative_models import GenerativeModel, GenerationConfig\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "os.environ['LOOKERSDK_BASE_URL'] = 'LOOKERSDK_BASE_URL' #https://instancename.looker.app\n",
        "os.environ['LOOKERSDK_CLIENT_ID'] = 'LOOKERSDK_CLIENT_ID'\n",
        "os.environ['LOOKERSDK_CLIENT_SECRET'] = 'LOOKERSDK_CLIENT_SECRET'\n",
        "sdk = looker_sdk.init40()"
      ],
      "metadata": {
        "id": "D0d26N_1OJYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_examples = 20\n",
        "\n",
        "hostname = \"LOOKER_HOSTNAME\" #https://instancename.looker.app\n",
        "model = \"LOOKER_MODEL\" #fashionly\n",
        "explore = \"LOOKER_EXPLORE\" #order_items\n",
        "\n",
        "# Enter here any history slugs that you want in the examples.\n",
        "# The rest will be generated from the most queried queries.\n",
        "\n",
        "history_slugs = [\n",
        "    '2ec605495cfc7f1f82a97d71217c203d',\n",
        "    'dfded515ee5bf66a81323f4ef4990863'\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "n3ebCl-RQm-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [\n",
        "    \"query.view\",\n",
        "    \"query.id\",\n",
        "    \"query.fields\",\n",
        "    \"query.filters\",\n",
        "    \"query.limit\",\n",
        "    \"query.column_limit\",\n",
        "    \"query.sorts\",\n",
        "    \"query.pivots_used\",\n",
        "    \"history.count\"\n",
        "]\n",
        "\n",
        "def get_fields(num_of_examples, model, explore, history_slugs):\n",
        "  body_queries = {\n",
        "      \"model\":\"system__activity\",\n",
        "      \"view\":\"history\",\n",
        "      \"fields\": fields,\n",
        "      \"filters\":{\"history.slug\": \"'\" + \"','\".join(history_slugs) + \"'\"},\n",
        "      \"query_timezone\":\"UTC\",\n",
        "      \"sorts\": [\"query.limit desc\", \"history.count desc\"],\n",
        "      \"limit\": max(1, num_of_examples-len(history_slugs))\n",
        "    }\n",
        "  results_queries = sdk.run_inline_query(result_format='json', body=body_queries)\n",
        "  results_queries_json = json.loads(results_queries)\n",
        "\n",
        "  body = {\n",
        "      \"model\":\"system__activity\",\n",
        "      \"view\":\"history\",\n",
        "      \"fields\": fields,\n",
        "      \"filters\":{\"query.model\":model, \"query.view\":explore},\n",
        "      \"query_timezone\":\"UTC\",\n",
        "      \"sorts\": [\"query.limit desc\", \"history.count desc\"],\n",
        "      \"limit\": max(5, num_of_examples-len(history_slugs))\n",
        "    }\n",
        "  results = sdk.run_inline_query(result_format='json', body=body)\n",
        "  results_json = json.loads(results)\n",
        "\n",
        "  merged_json = results_json + results_queries_json\n",
        "\n",
        "  print(merged_json)\n",
        "  return merged_json"
      ],
      "metadata": {
        "id": "CXe1q2gG_j7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_urls = []\n",
        "modified_fields = []\n",
        "\n",
        "results_json = get_fields(num_of_examples, model, explore, history_slugs)\n",
        "\n",
        "for i in results_json:\n",
        "  # Original URL\n",
        "  base_url = f\"{hostname}/explore/{model}\"\n",
        "\n",
        "  # Dynamic parameters to modify\n",
        "  try:\n",
        "    fields = i.get('query.fields').strip('[]').replace('\"', '')\n",
        "  except:\n",
        "    fields = \"\"\n",
        "\n",
        "  try:\n",
        "    filters_key_value_pairs = i.get('query.filters').replace('\"', '').strip(\"{}\").split(\",\")\n",
        "    filters = \"&\".join(f\"f[{pair.split(':')[0]}]={pair.split(':')[1]}\" for pair in filters_key_value_pairs).replace(' ', '+')\n",
        "  except:\n",
        "    filters = \"\"\n",
        "\n",
        "  try:\n",
        "    sorts = \"&\".join(json.loads(i.get('query.sorts').replace(' ', '+')))\n",
        "  except:\n",
        "    sorts = \"\"\n",
        "\n",
        "  limit = i.get('query.limit')\n",
        "  column_limit = i.get('query.column_limit')\n",
        "\n",
        "  # Construct the modified URL\n",
        "  modified_base_url = (\n",
        "      f\"{base_url}/\" # base\n",
        "      f\"{i.get('query.view')}?\" # explore\n",
        "  )\n",
        "\n",
        "  fields_url = (\n",
        "      f\"fields={fields}&\" # fields\n",
        "      f\"{filters}&\"\n",
        "      f\"sorts={sorts}&\"\n",
        "      f\"limit={limit}&\"\n",
        "      f\"column_limit={column_limit}&\"\n",
        "      f\"origin=share-expanded\"\n",
        "  )\n",
        "\n",
        "  modified_url = modified_base_url+fields_url\n",
        "\n",
        "  print(\"Modified URL:\", modified_url)\n",
        "  modified_urls.append(modified_url)\n",
        "  modified_fields.append(fields_url)\n",
        "\n",
        "print(modified_urls)\n",
        "print(modified_fields)\n"
      ],
      "metadata": {
        "id": "oGWu4xinfHAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "You are a specialized assistant that translates the fields parameter in a Looker Explore query URL into clear, natural language questions.\n",
        "\n",
        "By analyzing the provided fields and filters in the URL, you will generate a concise, one-sentence question that resembles something an average person would ask, avoiding technical jargon. Keep responses short and conversational.\n",
        "\n",
        "Example Input:\n",
        "fields=users.count&f[products.category]=Jeans&f[order_items.created_date]=1+years&limit=500&origin=share-expanded\n",
        "\n",
        "Example Output:\n",
        "How many users bought jeans last year?\n",
        "\n",
        "Now, generate the question for this input:\n",
        "'''\n",
        "\n",
        "parameters = {\"max_output_tokens\": 2500, \"temperature\": 0.2, \"candidate_count\": 1}\n",
        "vertexai.init(project=project_id, location=location)\n",
        "\n",
        "def generate_input(prompt_part):\n",
        "    model = GenerativeModel(\"gemini-pro\")\n",
        "    response =  model.generate_content(\n",
        "        contents=prompt + prompt_part,\n",
        "        generation_config=GenerationConfig(\n",
        "            temperature=0.2,\n",
        "            top_p=0.8,\n",
        "            top_k=40,\n",
        "            max_output_tokens=1000,\n",
        "            candidate_count=1\n",
        "        )\n",
        "    )\n",
        "    print(response.text)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "gcff9etVgC04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = []\n",
        "for field in modified_fields:\n",
        "  responses.append({'input': generate_input(field).strip(),'output': field})"
      ],
      "metadata": {
        "id": "mFA-gZMNgTHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint as pp\n",
        "for i in responses:\n",
        "  print('---')\n",
        "  print(i.get('input'))\n",
        "  print(i.get('output'))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mX7Ghc3e8dwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"examples.json\", \"w\") as file:\n",
        "    json.dump(responses, file, indent=2)"
      ],
      "metadata": {
        "id": "_7j5J1VLOCs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}